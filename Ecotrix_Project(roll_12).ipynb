{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from statsmodels.stats.diagnostic import het_breuschpagan\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import shapiro\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"reshaped_world_bank_data.xlsx\"  # Replace with your file path if different\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Clean the data\n",
        "data = data.replace(\"..\", pd.NA).dropna()\n",
        "# Explicitly convert specific columns to numeric\n",
        "for col in independent_variables + [dependent_variable]:\n",
        "    data[col] = pd.to_numeric(data[col], errors='coerce')\n",
        "\n",
        "# Re-apply dropna to remove any rows with NaNs introduced during type conversion\n",
        "data = data.dropna()\n",
        "\n",
        "# Define the dependent and independent variables\n",
        "dependent_variable = 'Agriculture, forestry, and fishing, value added (% of GDP)'\n",
        "independent_variables = [\n",
        "    'Employment in agriculture (% of total employment) (modeled ILO estimate)',\n",
        "    'Gross fixed capital formation (% of GDP)',\n",
        "    'Rural population (% of total population)'\n",
        "]\n",
        "\n",
        "# Prepare the regression dataset\n",
        "X = data[independent_variables]\n",
        "y = data[dependent_variable]\n",
        "\n",
        "# Add a constant to the independent variables\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the OLS regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print the regression results summary\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "pfVYQiJjzjrT",
        "outputId": "d89e0534-20f2-4f03-b4c4-023eddb8043a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'reshaped_world_bank_data.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-376765898.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"reshaped_world_bank_data.xlsx\"\u001b[0m  \u001b[0;31m# Replace with your file path if different\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Clean the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'reshaped_world_bank_data.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "nz3jjBfYr2jN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # Import the pandas library and assign it the alias 'pd'\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from statsmodels.stats.diagnostic import het_breuschpagan\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import shapiro\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"reshaped_world_bank_data.xlsx\"  # Replace with your file path if different\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Descriptive Statistics\n",
        "desc_stats = data.describe()\n",
        "print(\"Descriptive Statistics:\")\n",
        "print(desc_stats)\n",
        "\n",
        "# Relevant columns for box plots\n",
        "relevant_columns = [\n",
        "    \"Agriculture, forestry, and fishing, value added (% of GDP)\",\n",
        "    \"Employment in agriculture (% of total employment) (modeled ILO estimate)\",\n",
        "    \"Gross fixed capital formation (% of GDP)\",\n",
        "    \"Rural population (% of total population)\"\n",
        "]\n",
        "\n",
        "# Box Plots\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i, col in enumerate(relevant_columns, 1):\n",
        "    plt.subplot(2, 2, i)\n",
        "    sns.boxplot(y=data[col])\n",
        "    plt.title(f\"Box Plot: {col}\")\n",
        "    plt.ylabel(col)\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sYwWlD8We-sV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "from statsmodels.graphics.regressionplots import plot_partregress_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd  # Make sure pandas is imported\n",
        "\n",
        "# Define dependent and independent variables\n",
        "dependent_var = \"Agriculture, forestry, and fishing, value added (% of GDP)\"\n",
        "independent_vars = [\n",
        "    \"Employment in agriculture (% of total employment) (modeled ILO estimate)\",\n",
        "    \"Gross fixed capital formation (% of GDP)\",\n",
        "    \"Rural population (% of total population)\"\n",
        "]\n",
        "\n",
        "# Prepare data\n",
        "X = data[independent_vars]\n",
        "y = data[dependent_var]\n",
        "\n",
        "# Convert columns to numeric if they are not already\n",
        "X = X.apply(pd.to_numeric, errors='coerce')  # Convert to numeric, handle errors\n",
        "y = pd.to_numeric(y, errors='coerce')  # Convert to numeric, handle errors\n",
        "\n",
        "# Drop rows with any missing values after conversion\n",
        "X = X.dropna()\n",
        "y = y.dropna()\n",
        "\n",
        "# Filter the original DataFrame to match the rows in X and y\n",
        "data = data[data.index.isin(X.index)]\n",
        "\n",
        "# Add a constant to the independent variables\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit a regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Create large partial regression plots\n",
        "fig = plt.figure(figsize=(40, 25))  # Set figure size (width=40, height=25)\n",
        "plot_partregress_grid(model, fig=fig)\n",
        "plt.tight_layout(pad=3.0)  # Adjust padding for better spacing\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ka2l2pskMFKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Subset only the relevant variables for the heatmap (dependent and independent variables)\n",
        "heatmap_data = data[[\"Agriculture, forestry, and fishing, value added (% of GDP)\",\n",
        "                     \"Employment in agriculture (% of total employment) (modeled ILO estimate)\",\n",
        "                     \"Gross fixed capital formation (% of GDP)\",\n",
        "                     \"Rural population (% of total population)\"]]\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = heatmap_data.corr()\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True, square=True)\n",
        "plt.title(\"Heatmap of Variables in the Model\", fontsize=14)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4PGQTllofuRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.stats.api as sms\n",
        "from statsmodels.compat import lzip\n",
        "from statsmodels.stats.diagnostic import het_breuschpagan, het_goldfeldquandt, het_white\n",
        "\n",
        "# Residuals and fitted values\n",
        "residuals = model.resid\n",
        "fitted_values = model.fittedvalues\n",
        "\n",
        "# **1. Plot: Residuals vs Fitted Values**\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(fitted_values, residuals, alpha=0.7)\n",
        "plt.axhline(y=0, color=\"red\", linestyle=\"--\")\n",
        "plt.title(\"Residuals vs Fitted Values\")\n",
        "plt.xlabel(\"Fitted Values\")\n",
        "plt.ylabel(\"Residuals\")\n",
        "plt.show()\n",
        "\n",
        "# Define independent_variables within the cell if it's not already defined\n",
        "independent_variables = [\n",
        "    \"Employment in agriculture (% of total employment) (modeled ILO estimate)\",\n",
        "    \"Gross fixed capital formation (% of GDP)\",\n",
        "    \"Rural population (% of total population)\"\n",
        "]\n",
        "\n",
        "# **2. Residuals vs Individual Regressors**\n",
        "for var in independent_variables:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(data[var], residuals, alpha=0.7)\n",
        "    plt.axhline(y=0, color=\"red\", linestyle=\"--\")\n",
        "    plt.title(f\"Residuals vs {var}\")\n",
        "    plt.xlabel(var)\n",
        "    plt.ylabel(\"Residuals\")\n",
        "    plt.show()\n",
        "\n",
        "# **3. Goldfeld-Quandt Test**\n",
        "gq_test = het_goldfeldquandt(residuals, X.iloc[:, 1:])\n",
        "print(\"Goldfeld-Quandt Test:\")\n",
        "print(f\"F-statistic: {gq_test[0]}, p-value: {gq_test[1]}\")\n",
        "print(\"Observation: Reject H0 (homoskedasticity) if p-value < 0.05.\")"
      ],
      "metadata": {
        "id": "Mr9zw7t4cC5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# **1. Q-Q Plot: Standardized Residuals vs Standard Normal**\n",
        "standardized_residuals = (residuals - residuals.mean()) / residuals.std()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sm.qqplot(standardized_residuals, line=\"45\", fit=True)\n",
        "plt.title(\"Q-Q Plot of Standardized Residuals\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# **2. Shapiro-Wilk Test**\n",
        "shapiro_test = stats.shapiro(standardized_residuals)\n",
        "print(\"\\nShapiro-Wilk Test:\")\n",
        "print(f\"Statistic: {shapiro_test.statistic}, p-value: {shapiro_test.pvalue}\")\n",
        "print(\"Observation: Reject H0 (normality) if p-value < 0.05.\")"
      ],
      "metadata": {
        "id": "nWseLeO9PFIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert X_numeric to a NumPy array for matrix operations\n",
        "X_array = X_numeric.to_numpy()\n",
        "\n",
        "# Calculate the Hat Matrix (H)\n",
        "hat_matrix = X_array @ np.linalg.inv(X_array.T @ X_array) @ X_array.T\n",
        "leverages = np.diag(hat_matrix)  # Diagonal elements of the Hat Matrix\n",
        "\n",
        "# Threshold for High Leverage Points\n",
        "n = X_array.shape[0]  # Number of observations\n",
        "p = X_array.shape[1]  # Number of predictors (including intercept)\n",
        "leverage_threshold = 2 * p / n\n",
        "\n",
        "# Identify high leverage points\n",
        "high_leverage_points = np.where(leverages > leverage_threshold)[0]\n",
        "\n",
        "print(\"High Leverage Points:\")\n",
        "print(f\"Indices: {high_leverage_points}\")\n",
        "print(f\"Threshold: {leverage_threshold}\")\n",
        "print(f\"Leverages: {leverages[high_leverage_points]}\")\n",
        "\n",
        "# Standardized Residuals\n",
        "standardized_residuals = (residuals - residuals.mean()) / residuals.std()\n",
        "\n",
        "# Cook's Distance\n",
        "cooks_distance = (standardized_residuals**2 / p) * (leverages / (1 - leverages)**2)\n",
        "\n",
        "# Threshold for Cook's Distance (rule of thumb: D > 4/n)\n",
        "cooks_threshold = 4 / n\n",
        "influential_points = np.where(cooks_distance > cooks_threshold)[0]\n",
        "\n",
        "print(\"\\nInfluential Points based on Cook's Distance:\")\n",
        "print(f\"Indices: {influential_points}\")\n",
        "print(f\"Threshold: {cooks_threshold}\")\n",
        "print(f\"Cook's Distances: {cooks_distance[influential_points]}\")\n",
        "\n",
        "# Plot: Leverages vs Cook's Distance\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(leverages, cooks_distance, alpha=0.7)\n",
        "plt.axhline(y=cooks_threshold, color=\"red\", linestyle=\"--\", label=\"Cook's Distance Threshold\")\n",
        "plt.axvline(x=leverage_threshold, color=\"blue\", linestyle=\"--\", label=\"Leverage Threshold\")\n",
        "plt.xlabel(\"Leverage\")\n",
        "plt.ylabel(\"Cook's Distance\")\n",
        "plt.title(\"Leverage vs Cook's Distance\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "G36FUs7n2A-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# Clean column names for Patsy compatibility\n",
        "data_clean = data.rename(columns=lambda x: x.replace(\" \", \"_\")\n",
        "                                      .replace(\",\", \"\")\n",
        "                                      .replace(\"(\", \"\")\n",
        "                                      .replace(\")\", \"\")\n",
        "                                      .replace(\"%\", \"percent\"))\n",
        "\n",
        "# Update variable names\n",
        "dependent_var = \"Agriculture_forestry_and_fishing_value_added_percent_of_GDP\"\n",
        "independent_vars = [\n",
        "    \"Employment_in_agriculture_percent_of_total_employment_modeled_ILO_estimate\",\n",
        "    \"Gross_fixed_capital_formation_percent_of_GDP\",\n",
        "    \"Rural_population_percent_of_total_population\"\n",
        "]\n",
        "\n",
        "# Fit unrestricted model (full model)\n",
        "formula_unrestricted = f\"{dependent_var} ~ {' + '.join(independent_vars)}\"\n",
        "unrestricted_model = smf.ols(formula_unrestricted, data=data_clean).fit()\n",
        "\n",
        "# Fit restricted model (null model)\n",
        "restricted_formula = f\"{dependent_var} ~ Employment_in_agriculture_percent_of_total_employment_modeled_ILO_estimate\"\n",
        "restricted_model = smf.ols(restricted_formula, data=data_clean).fit()\n",
        "\n",
        "# ANOVA Comparison between Unrestricted and Restricted Models\n",
        "anova_results = sm.stats.anova_lm(restricted_model, unrestricted_model, typ=1)\n",
        "\n",
        "# Print results\n",
        "print(\"ANOVA Results (Model Comparison):\")\n",
        "print(anova_results)\n",
        "\n",
        "# Theoretical Hypotheses Testing\n",
        "print(\"\\nTheoretical Hypotheses Testing (Full Model):\")\n",
        "print(unrestricted_model.summary())\n"
      ],
      "metadata": {
        "id": "nJPlShJwHAFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Subset the independent variables from the data (ensure it's numeric and excludes constant)\n",
        "X_independent = X_numeric.drop(columns=[\"const\"])  # Drop constant if present\n",
        "\n",
        "# **1. Condition Indices**\n",
        "# Singular Value Decomposition (SVD)\n",
        "u, s, vh = np.linalg.svd(X_independent, full_matrices=False)\n",
        "condition_indices = s[0] / s  # Condition Index: ratio of largest singular value to others\n",
        "print(\"Condition Indices:\")\n",
        "print(condition_indices)\n",
        "\n",
        "# Condition Number (largest condition index)\n",
        "condition_number = np.max(condition_indices)\n",
        "print(f\"\\nCondition Number: {condition_number}\")\n",
        "\n",
        "# **2. Variance Inflation Factors (VIFs)**\n",
        "vif_data = pd.DataFrame({\n",
        "    \"Variable\": X_independent.columns,\n",
        "    \"VIF\": [variance_inflation_factor(X_independent.values, i) for i in range(X_independent.shape[1])]\n",
        "})\n",
        "vif_data[\"IVIF\"] = 1 / vif_data[\"VIF\"]  # Inverse VIF\n",
        "print(\"\\nVariance Inflation Factors (VIFs) and IVIFs:\")\n",
        "print(vif_data)\n",
        "\n",
        "# **Observations**\n",
        "print(\"\\nObservations:\")\n",
        "print(\"1. Condition indices above 30 may indicate severe multicollinearity.\")\n",
        "print(\"2. Condition number > 30 suggests multicollinearity.\")\n",
        "print(\"3. VIF > 10 indicates problematic multicollinearity, though thresholds can vary.\")\n",
        "print(\"4. IVIFs provide insight into the percentage of variance explained by each predictor.\")\n"
      ],
      "metadata": {
        "id": "8Te41bVRLRBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y8GTneoWL3y_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}